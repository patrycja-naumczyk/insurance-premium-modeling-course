{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# wizualizacje\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedShuffleSplit\n",
    "from sklearn.linear_model import PoissonRegressor, GammaRegressor\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, r2_score #, d2_absolute_error_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression, mutual_info_classif, f_regression, RFECV, SequentialFeatureSelector\n",
    "\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# ustawienie szerokiego ekranu wyświetlacza JNotebook\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# opcje wyświetlania w Pandas\n",
    "# - maks. 55 kolumn\n",
    "# - maks. 101 wierszy\n",
    "# - liczby w notacji dziesiętnej z czterema zerami po przecinku\n",
    "pd.set_option('display.max_columns', 55)\n",
    "pd.set_option('display.max_rows', 101)\n",
    "pd.set_option('display.float_format', lambda x: f\"{x:.4f}\")\n",
    "\n",
    "# opcje formatowania wykresów matplotlib\n",
    "# - etykiety osi: bold\n",
    "# - tekst: bold\n",
    "# - domyślny rozmiar fontu=14\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['font.weight'] = 'bold'\n",
    "plt.rcParams['font.size'] = '14'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wczytanie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zadanie 1\n",
    "\n",
    "filepath = r\"C:\\Users\\pnaumczyk\\Documents\\Dane\\Python_modelowanie_crashCourse\\train.csv\"\n",
    "cats_dow = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Weekend\"]\n",
    "dow_dtype = pd.api.types.CategoricalDtype(categories=cats_dow, ordered=True)\n",
    "\n",
    "miesiac_zima = [\"January\", \"February\", \"December\"]\n",
    "miesiac_wiosna = [\"March\", \"April\", \"May\"]\n",
    "miesiac_lato = [\"June\", \"July\", \"August\"]\n",
    "miesiac_jesien = [\"September\", \"October\", \"November\"]\n",
    "\n",
    "cats_season = [\"wiosna\", \"lato\", \"jesien\", \"zima\"]\n",
    "season_dtype =  pd.api.types.CategoricalDtype(categories=cats_season, ordered=True)\n",
    "\n",
    "cat_cols = [\n",
    "    'pora_dnia_przejazdu',\n",
    "    'dzien_tygodnia_cat', \n",
    "    'stacja_start_cat',  \n",
    "    'stacja_finisz_cat', \n",
    "    'rodzaj_pociagu_cat', \n",
    "    'pora_roku_cat'\n",
    "]\n",
    "num_cols = [\n",
    "    'opoznienie_start',\n",
    "    'czy_szkoda',\n",
    "    'wyplata_szkoda'\n",
    "]\n",
    "\n",
    "\n",
    "df = (\n",
    "    pd.read_csv(filepath, sep=';')\n",
    "    \n",
    "    .assign(\n",
    "        **{\n",
    "             k: lambda df_, col = k: pd.to_datetime(df_[col])\n",
    "                for k in [\n",
    "                    'Kiedy jechał*ś?'\n",
    "                ]\n",
    "        },\n",
    "        **{ k: lambda df_, col = k: pd.to_numeric(df_[col], downcast='float')\n",
    "                for k in [\n",
    "                    'Koszt podróży:'\n",
    "                ]\n",
    "        },\n",
    "        **{ k: lambda df_, col = k: pd.to_numeric(df_[col], downcast='integer')\n",
    "                for k in [\n",
    "                    'Liczba minut opóźnienia na starcie:', 'Liczba minut opóźnienia na mecie:'\n",
    "                ]\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    .astype({\n",
    "        **{ k: 'string' \n",
    "               for k in [\n",
    "                   'Stacja początkowa:', 'Stacja końcowa:', 'Jak wrażenia z podróży? :D (nieobowiązkowe)', 'Uwagi (nieobowiązkowe):'\n",
    "               ]            \n",
    "        },\n",
    "        **{ k: 'category' \n",
    "               for k in [\n",
    "                   'Rodzaj pociągu:', 'Pora dnia:'\n",
    "               ]            \n",
    "        }\n",
    "    })\n",
    "    \n",
    "    .rename(columns={\n",
    "        'Kiedy jechał*ś?'         : 'data_przejazdu',\n",
    "        'Stacja początkowa:'      : 'stacja_start',\n",
    "        'Stacja końcowa:'         : 'stacja_finisz',\n",
    "        'Rodzaj pociągu:'         : 'rodzaj_pociagu',\n",
    "        'Uwagi (nieobowiązkowe):' : 'uwagi',\n",
    "        'Koszt podróży:'          : 'cena_biletu',\n",
    "        'Pora dnia:'              : 'pora_dnia_przejazdu',\n",
    "        'Liczba minut opóźnienia na starcie:' : 'opoznienie_start',\n",
    "        'Liczba minut opóźnienia na mecie:'   : 'opoznienie_finisz',\n",
    "        'Jak wrażenia z podróży? :D (nieobowiązkowe)' : 'wrazenia'\n",
    "    })\n",
    "    \n",
    "    .drop(columns=['wrazenia', 'uwagi'])\n",
    "    .drop(index=[30, 50])\n",
    "    \n",
    "    .assign(\n",
    "        pora_dnia_przejazdu = lambda df_: np.select(\n",
    "        [\n",
    "            (df_.pora_dnia_przejazdu.isnull() & df_.stacja_start.str.contains('Legionowo')).astype(bool),\n",
    "            (df_.pora_dnia_przejazdu.isnull() & df_.stacja_finisz.str.contains('Legionowo')).astype(bool),\n",
    "            (df_.pora_dnia_przejazdu.isnull() & df_.stacja_finisz.str.contains('Gdask')).astype(bool)\n",
    "        ],\n",
    "        [\n",
    "            'rano',\n",
    "            'popołudnie',\n",
    "            'popołudnie'            \n",
    "        ],\n",
    "        df_.pora_dnia_przejazdu\n",
    "    ))\n",
    "    \n",
    "    .reset_index(drop=True)\n",
    "    \n",
    "    .assign(\n",
    "        czy_szkoda = lambda df_: np.select(\n",
    "            [\n",
    "                df_.opoznienie_finisz.gt(10) & df_.opoznienie_finisz.le(40),\n",
    "                df_.opoznienie_finisz.gt(40)\n",
    "            ],\n",
    "            [\n",
    "                1,\n",
    "                2\n",
    "            ],\n",
    "            0\n",
    "        ),\n",
    "        \n",
    "        wyplata_szkoda = lambda df_: np.where(\n",
    "            df_.opoznienie_finisz.gt(10),\n",
    "            df_.cena_biletu * np.exp(df_.opoznienie_finisz.div(100)) * df_.czy_szkoda,\n",
    "            0.0\n",
    "        )\n",
    "\n",
    "    )\n",
    "    \n",
    "    .sort_values(by='data_przejazdu')\n",
    "    .reset_index(drop=True)\n",
    "    \n",
    "    .assign(\n",
    "        dzien_tygodnia = lambda df_: df_.data_przejazdu.dt.day_name().astype('category'),\n",
    "        dzien_tygodnia_cat = lambda df_: np.where(\n",
    "            df_.dzien_tygodnia.eq('Sunday') | df_.dzien_tygodnia.eq('Saturday') | df_.dzien_tygodnia.eq('Monday'),\n",
    "            'Weekend',\n",
    "            df_.dzien_tygodnia\n",
    "        ),\n",
    "        miesiac = lambda df_: df_.data_przejazdu.dt.month_name().astype('category'),\n",
    "        pora_roku = lambda df_: np.select(\n",
    "            [\n",
    "                df_.miesiac.isin(miesiac_zima),\n",
    "                df_.miesiac.isin(miesiac_wiosna),\n",
    "                df_.miesiac.isin(miesiac_lato),\n",
    "                df_.miesiac.isin(miesiac_jesien)\n",
    "            ],\n",
    "            [\n",
    "                \"zima\",\n",
    "                \"wiosna\",\n",
    "                \"lato\",\n",
    "                \"jesien\"\n",
    "            ],\n",
    "            \"brak_danych\"\n",
    "        ),        \n",
    "        stacja_start_cat = lambda df_: np.select(\n",
    "            [\n",
    "                df_.stacja_start.str.contains(\"Warszawa\").astype(bool),\n",
    "                df_.stacja_start.str.contains(\"Legionowo\").astype(bool),\n",
    "                (df_.stacja_start.str.contains(\"Gdańsk\") | df_.stacja_start.str.contains(\"Gdask\")).astype(bool)\n",
    "            ],\n",
    "            [\n",
    "                \"Warszawa\",\n",
    "                \"Legionowo\",\n",
    "                \"Gdańsk\"\n",
    "                \n",
    "            ],\n",
    "            \"Inne\"\n",
    "        ),\n",
    "        stacja_finisz_cat = lambda df_: np.select(\n",
    "            [\n",
    "                df_.stacja_finisz.str.contains(\"Warszawa\").astype(bool),\n",
    "                df_.stacja_finisz.str.contains(\"Legionowo\").astype(bool),\n",
    "                (df_.stacja_finisz.str.contains(\"Gdańsk\") | df_.stacja_finisz.str.contains(\"Gdask\")).astype(bool)\n",
    "            ],\n",
    "            [\n",
    "                \"Warszawa\",\n",
    "                \"Legionowo\",\n",
    "                \"Gdańsk\"\n",
    "                \n",
    "            ],\n",
    "            \"Inne\"\n",
    "        ),  \n",
    "        rodzaj_pociagu_cat = lambda df_: np.where(df_.rodzaj_pociagu.eq(\"EIC\"), '\"Zwykły\" InterCity', df_.rodzaj_pociagu)\n",
    "    )\n",
    "    \n",
    "    .astype({\n",
    "        **{ k: 'category' \n",
    "               for k in [\n",
    "                   'stacja_start_cat', 'stacja_finisz_cat', 'rodzaj_pociagu_cat'\n",
    "               ]            \n",
    "        },      \n",
    "    })\n",
    "    \n",
    "    .assign(\n",
    "        dzien_tygodnia_cat = lambda df_: df_.dzien_tygodnia_cat.astype(dow_dtype),\n",
    "        pora_roku_cat = lambda df_: df_.pora_roku.astype(season_dtype)\n",
    "    )\n",
    "    \n",
    "    .drop(columns=[\n",
    "        'data_przejazdu', 'stacja_start', 'stacja_finisz', 'rodzaj_pociagu', 'cena_biletu', 'dzien_tygodnia', 'miesiac', 'pora_roku', 'opoznienie_finisz'\n",
    "    ])\n",
    "\n",
    "    .reindex(columns = cat_cols + num_cols)\n",
    "\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing (podział na set treningowy i testowy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.3, stratify=df.czy_szkoda, random_state=42)\n",
    "print(\n",
    "    f\"Rozmiar testowego: {df_test.shape}\\n\"\n",
    "    f\"Rozmiar treningowego: {df_train.shape}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spis treści\n",
    "1. [Automatyczne przekształcenia zmiennych](#column_transformer)\n",
    "2. [Walidacja krzyżowa](#cv)\n",
    "3. [Selekcja zmiennych wyjaśniających](#fs)\n",
    "4. [Ścieżki przekształceń](#pipeline)\n",
    "\n",
    "***\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='column_transformer'>Automatyczne przekształcenia zmiennych</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stwórz transformer column_trans przekształcający dane wejściowe: OneHotEncoding dla zmiennych kategorialnych, MinMaxScaler dla ciagłych, zmienne wyjaśniane bez przekształceń <br>\n",
    "Wyświetl jego zawartość"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Dopasuj transformer na danych treningowych tworząc zmienną X_train_coded. Co jest efektem przekształcenia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Wyświetl parametry poszczególnych przekształceń w column_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Wyświetl nazwy poszczególnych kolumn po przekształceniu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Zastosuj przekształcenie kolumn osobno na danych testowych i treningowych tworząc zmienne X_train_coded oraz X_test_coded. Jaki jest ich format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Stwórz zmienne df_train_tans oraz df_test_trans typu pd.DataFrame, przechowujące przekształcone dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Usuń z podanych wzorów kolumny ze zmiennymi wyjaśnianymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='cv'>Walidacja krzyżowa</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zdefiniuj zmienną params jako parametry regresji Poissona wyszukując wśród wartości:\n",
    "    1. parametr alpha: 100 wartości logarytmicznie rozkładających sie od 10^-20 do 10\n",
    "    2. parametr solver: w zależności od wersji scikit-learn: albo wyłącznie 'lbfgs', albo którekolwiek spośród: {'lbfgs', 'newton-cholesky'}\n",
    "    3. parametr max_iter: 100 lub 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Stwórz zmienną poisson_gscv zawierającą wyniki GridSearchCV na zbiorze df_train_trans dla zmiennej wyjaśnianej czy_szkoda:\n",
    "    1. model - regresja Poissona\n",
    "    2. parametry - z zadania 1\n",
    "    3. scoring - mean_poisson_deviance\n",
    "    4. typ walidacji krzyżowej - stratified k fold z 10 foldami\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Wyświetl wyniki walidacji krzyżowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Wyświetl najlepsze wyniki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Zrób grid search uwzględniając trzy metryki: \n",
    "    1. mean_poisson_deviance\n",
    "    2. r2_score\n",
    "    3. (jeśli masz scikit-learn powyżej 1.1) d2_absolute_error_score\n",
    "    \n",
    "Wyświetl najlepsze parametry dopasowania dla każdej z metryk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Przeprowadź grid search jak w punkcie 5, ale ze StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Policz metryki na zbiorze testowym z dopasowaniem domyślnym oraz z dopasowaniem alpha według grid search. Porównaj."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='fs'>Selekcja zmiennych wyjaśniających</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Przelicz i wyświetl wartości informacji wzajemnej dla zmiennej czy_szkoda z użyciem SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Jakie cztery zmienne maja największą informację wzajemną ze zmienną czy_szkoda? Jakie mają największy związek liniowy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. A. (dodatkowe) Ustaw w informacji wzajemnej - które zmienne są kategorialne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Przeprowadź dopasowanie RFECV dla zmiennej czy_szkoda i 10 foldów cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Wyświetl wyniki dopasowania RFECV w postaci data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Jakie zmienne pozostały po selekcji RFECV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Powtórz dopasowanie RFECV tym razem ustalając parametr alfa jako jeden z tych z grid search. Czy to zmieniło listę zmiennych?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Przeprowadź selekcję wprzód z użyciem SequentialFeatureSelector. Jakie zmienne zostały w modelu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Powtórz punkt 7 z parametrem alpha wyliczonym z grid search. Czy zmieniło to wyniki?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='pipeline'>Ścieżki przekształceń</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Stwórz pipeline zawierający przekształcenie kolumn zdefiniowane wcześniej oraz modelowanie PoissonRegressor. Wyświetl pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Wyświetl parametry pipeline'u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Przeprowadź optymalizację parametrów PoissonRegressor przy użyciu GridSearchCV, ale bez \"information leakege\" podczas walidacji krzyżowej (wykorzystaj pipeline). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Porównaj uzyskane parametry oraz metryki oceniające model z wcześniej uzyskanymi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Stwórz nowy pipeline z dwiema metodami skalowania dla zmiennych numerycznych (StandardScaler orpócz MinMaxScaler). Porównaj, który daje najlepsze wyniki pod względem r^2 oraz neg_mean_poisson_deviance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Połącz powyższe i przelicz optymalne parametry wraz z wyborem ścieżki przetwarzania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Porównaj metryki uzyskane na przewidywaniu zbioru testowego na podstawie danych z punktu 6 i wcześniejszych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
